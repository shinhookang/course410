{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"ee-notebook-buttons\" align=\"left\">\n",
    "    <td><a target=\"_parent\"  href=\"https://github.com/gee-community/geemap/tree/master/tutorials/Image/14_registering_images.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td>\n",
    "    <td><a target=\"_parent\"  href=\"https://nbviewer.jupyter.org/github/gee-community/geemap/blob/master/tutorials/Image/14_registering_images.ipynb\"><img width=26px src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Jupyter_logo.svg/883px-Jupyter_logo.svg.png\" />Notebook Viewer</a></td>\n",
    "    <td><a target=\"_parent\"  href=\"https://colab.research.google.com/github/gee-community/geemap/blob/master/tutorials/Image/14_registering_images.ipynb\"><img width=26px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Images\n",
    "The Earth Engine image registration algorithm is designed to be a final, post-ortho, fine-grained step in aligning images. It is assumed that the images to be registered have already gone through initial alignment stages, so they are already within a few degrees of rotation of one another, and differ by only small translations. The registration uses a “rubber-sheet” technique, allowing local image warping to correct for orthorectification errors and other artifacts from earlier processing. The underlying alignment technique is image correlation, so the bands for the input and reference images must be visually similar in order for the algorithm to compute an accurate alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Earth Engine API and geemap\n",
    "Install the [Earth Engine Python API](https://developers.google.com/earth-engine/python_install) and [geemap](https://github.com/gee-community/geemap). The **geemap** Python package is built upon the [ipyleaflet](https://github.com/jupyter-widgets/ipyleaflet) and [folium](https://github.com/python-visualization/folium) packages and implements several methods for interacting with Earth Engine data layers, such as `Map.addLayer()`, `Map.setCenter()`, and `Map.centerObject()`.\n",
    "The following script checks if the geemap package has been installed. If not, it will install geemap, which automatically installs its [dependencies](https://github.com/gee-community/geemap#dependencies), including earthengine-api, folium, and ipyleaflet.\n",
    "\n",
    "**Important note**: A key difference between folium and ipyleaflet is that ipyleaflet is built upon ipywidgets and allows bidirectional communication between the front-end and the backend enabling the use of the map to capture user input, while folium is meant for displaying static data only ([source](https://blog.jupyter.org/interactive-gis-in-jupyter-with-ipyleaflet-52f9657fa7a)). Note that [Google Colab](https://colab.research.google.com/) currently does not support ipyleaflet ([source](https://github.com/googlecolab/colabtools/issues/60#issuecomment-596225619)). Therefore, if you are using geemap with Google Colab, you should use [`import geemap.foliumap`](https://github.com/gee-community/geemap/blob/master/geemap/foliumap.py). If you are using geemap with [binder](https://mybinder.org/) or a local Jupyter notebook server, you can use [`import geemap`](https://github.com/gee-community/geemap/blob/master/geemap/geemap.py), which provides more functionalities for capturing user input (e.g., mouse-clicking and moving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs geemap package\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import geemap\n",
    "except ImportError:\n",
    "    print(\"geemap package not installed. Installing ...\")\n",
    "    subprocess.check_call([\"python\", \"-m\", \"pip\", \"install\", \"geemap\"])\n",
    "\n",
    "# Checks whether this notebook is running on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    import geemap.foliumap as emap\n",
    "except:\n",
    "    import geemap as emap\n",
    "\n",
    "# Authenticates and initializes Earth Engine\n",
    "import ee\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an interactive map \n",
    "The default basemap is `Google Satellite`. [Additional basemaps](https://github.com/gee-community/geemap/blob/master/geemap/geemap.py#L13) can be added using the `Map.add_basemap()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=[40, -100], zoom=4)\n",
    "Map.add_basemap(\"ROADMAP\")  # Add Google Map\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image displacement\n",
    "There are two steps to registering an image: Determining the displacement image using `displacement()`, and then applying it with `displace()`. The required inputs are the pair of images to register, and a maximum displacement parameter (`maxOffset`).\n",
    "\n",
    "The `displacement()` algorithm takes a reference image, a maximum displacement parameter (`maxOffset`), and two optional parameters that modify the algorithm behaviour. The output is a displacement image with bands `dx` and `dy` which give the X and Y components (in meters) of the displacement vector at each pixel.\n",
    "\n",
    "All bands of the calling and reference images are used for matching during registration, so the number of bands must be exactly equal. The input bands must be visually similar for registration to succeed. If that is not the case, it may be possible to pre-process them (e.g. smoothing, edge detection) to make them appear more similar. The registration computations are performed using a multiscale, coarse-to-fine process, with (multiscale) working projections that depend on three of the projections supplied to the algorithm:\n",
    "\n",
    "1. the default projection of the calling image (Pc)\n",
    "2. the default projection of the reference image (Pr)\n",
    "3. the output projection (Po)\n",
    "\n",
    "The highest resolution working projection (*Pw* will be in the CRS of *Pr*, at a scale determined by the coarsest resolution of these 3 projections, to minimize computation. The results from *Pr* are then resampled to be in the projection specified by the input ‘projection’ parameter.\n",
    "\n",
    "The output is a displacement image with the following bands:\n",
    "\n",
    "`dx`\n",
    "\n",
    "* For a given reference image pixel location, this band contains the distance in the X direction that must be travelled to arrive at the matching location in the calling image. Units are in geodesic meters.\n",
    "\n",
    "`dy`\n",
    "* For a given reference image pixel location, this band contains the distance in the Y direction that must be travelled to arrive at the matching location in the calling image. Units are in geodesic meters.\n",
    "\n",
    "`confidence`\n",
    "\n",
    "* This is a per-pixel estimate of displacement confidence (where 0 is low confidence and 1 is high confidence) based on the correlation scores in regions where valid matches were found. In regions where no matches were found, confidence is estimated from nearby correlations using a Gaussian kernel to provide higher weight to nearby correlations.\n",
    "The following example computes the magnitude and angle of displacement between two high-resolution [Terra Bella](https://terrabella.google.com/) images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Load the two images to be registered.\n",
    "image1 = ee.Image(\"SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL/s01_20150502T082736Z\")\n",
    "image2 = ee.Image(\"SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL/s01_20150305T081019Z\")\n",
    "\n",
    "# Use bicubic resampling during registration.\n",
    "image1Orig = image1.resample(\"bicubic\")\n",
    "image2Orig = image2.resample(\"bicubic\")\n",
    "\n",
    "# Choose to register using only the 'R' bAnd.\n",
    "image1RedBAnd = image1Orig.select(\"R\")\n",
    "image2RedBAnd = image2Orig.select(\"R\")\n",
    "\n",
    "# Determine the displacement by matching only the 'R' bAnds.\n",
    "displacement = image2RedBAnd.displacement(\n",
    "    **{\"referenceImage\": image1RedBAnd, \"maxOffset\": 50.0, \"patchWidth\": 100.0}\n",
    ")\n",
    "\n",
    "# Compute image offset And direction.\n",
    "offset = displacement.select(\"dx\").hypot(displacement.select(\"dy\"))\n",
    "angle = displacement.select(\"dx\").atan2(displacement.select(\"dy\"))\n",
    "\n",
    "# Display offset distance And angle.\n",
    "Map.addLayer(offset, {\"min\": 0, \"max\": 20}, \"offset\")\n",
    "Map.addLayer(angle, {\"min\": -math.pi, \"max\": math.pi}, \"angle\")\n",
    "Map.setCenter(37.44, 0.58, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warping an image\n",
    "There are two ways to warp an image to match another image: `displace()` or `register()`. The `displace()` algorithm takes a displacement image having `dx` and `dy` bands as the first two bands, and warps the image accordingly. The output image will be the result of warping the bands of the input image by the offsets present in the displacement image. Using the displacements computed in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the computed displacement to register all Original bAnds.\n",
    "registered = image2Orig.displace(displacement)\n",
    "\n",
    "# Show the results of co-registering the images.\n",
    "visParams = {\"bands\": [\"R\", \"G\", \"B\"], \"max\": 4000}\n",
    "Map.addLayer(image1Orig, visParams, \"Reference\")\n",
    "Map.addLayer(image2Orig, visParams, \"BefOre Registration\")\n",
    "Map.addLayer(registered, visParams, \"After Registration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't need the displacement bands, Earth Engine provides the `register()` method, which is a shortcut for calling `displacement()` followed by `displace()`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsoRegistered = image2Orig.register(\n",
    "    **{\"referenceImage\": image1Orig, \"maxOffset\": 50.0, \"patchWidth\": 100.0}\n",
    ")\n",
    "Map.addLayer(alsoRegistered, visParams, \"Also Registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the results of `register()` differ from the results of `displace()`. This is because a different set of bands was used in the two approaches: `register()` always uses all bands of the input images, while the `displacement()` example used only the red band before feeding the result to `displace()`. Note that when multiple bands are used, if band variances are very different this could over-weight the high-variance bands, since the bands are jointly normalized when their spatial correlation scores are combined. This illustrates the importance of selecting band(s) that are visually the most similar when registering. As in the previous example, use `displacement()` and `displace()` for control over which bands are used to compute displacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Earth Engine data layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayerControl()\n",
    "Map"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
