# Apache Spark

Create a virtual environment. `python -m venv .venv`

Activate the virtual environment. `source .venv/bin/activate`

Deactivate the virtual environment. `deactivate`

## Install 

```bash
pip install pyspark
```

When PySpark is initialized, it launches a Java Virtual Machine (JVM) process to run the Spark runtime. This runtime encompasses essential libraries such as Spark Core, SQL, Streaming, MLlib, and GraphX.

For Mac, install JDK through `brew install openjdk@11`

## Run PySpark

Type `pyspark` in a shell. 
Spark shell is ready.

<img src="./figure/pyspark-ss.png" alt="Logo" height="300"/>

## Quickstart 

Use Apache Spark examples.
[DataFrame](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html)
[Spark Connect](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_connect.html)
[Pandas API on Spark](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_ps.html)

